models:
  - name: bert-large-cased-whole-word-masking-finetuned-squad
    launchers:
      - framework: tvm
        model: /Users/admin/workspace/open_model_zoo/models/tvm_compiled/compiled/bert-large-cased-whole-word-masking-finetuned-squad/bert-large-cased-whole-word-masking-finetuned-squad.so
        adapter: 
          type: bert_question_answering
          start_token_logits_output: "0"
          end_token_logits_output: "1"
        device: cpu
        session: local
        vm: false
        inputs:
          - name: "input_ids"
            type: INPUT
            shape: 1, 384
            layout: NC
            value: "input_ids"
          - name: "attention_mask"
            type: INPUT
            shape: 1, 384
            layout: NC
            value: 'input_mask'
          - name: 'token_type_ids'
            type: INPUT
            shape: 1, 384
            layout: NC
            value: 'segment_ids'
        _input_precision:
            - input_ids:I64
            - attention_mask:I64
            - token_type_ids:I64

    datasets:
      - name: squad_v1_1_msl384_mql64_ds128_lowercase
        reader:
          type: annotation_features_extractor
          features:
            - input_ids
            - input_mask
            - segment_ids
        postprocessing:
          - type: extract_answers_tokens
            max_answer: 30
            n_best_size: 20
        metrics:
          - name: 'F1'
            type: 'f1'
            reference: 92.9
          - name: 'EM'
            type: 'exact_match'
            reference: 86.7
 
        # Convert annotations with: convert_annotation squad --testing_file path/to/dev1.1.json --vocab_file path/to/vocab.txt --max_seq_length 384 --lower_case False
        annotation: /Users/admin/workspace/scripts/annotations/SQuAD/v1.1/bert-large-cased-whole-word-masking-finetuned-squad/squad.pickle